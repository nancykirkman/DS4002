# -*- coding: utf-8 -*-
"""DS4002_Fungi_Image_Classification.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1YLKpJTQWLLt2OlHtK__at1veKbtZYIdW
"""

!pip install tensorflow

pip install --upgrade tensorflow

import tensorflow as tf
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import keras
import os
import requests
import zipfile
import random
import seaborn as sns
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.preprocessing.image import load_img
from tensorflow.keras.preprocessing.image import img_to_array
import PIL.Image
from io import BytesIO
import cv2
import matplotlib.image as mpimg
import seaborn as sns
from tqdm import tqdm
from keras.callbacks import EarlyStopping, ModelCheckpoint
from sklearn.metrics import confusion_matrix , accuracy_score
from sklearn.metrics import classification_report
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
import glob
import pandas as pan
import matplotlib.pyplot as plotter
import warnings
warnings.filterwarnings('ignore')
from IPython.display import Image
from tensorflow.keras.applications import VGG19
from tensorflow.keras import models, layers
from tensorflow.keras.models import load_model
import shutil
from keras.callbacks import EarlyStopping

# Path to the zip file
fungi_path = "/content/drive/MyDrive/DS4002/defungi.zip"

# Directory where contents are extracted
fungi_output = "/content/drive/MyDrive/DS4002/Unedited"

# Step 1: Extract the contents of the archive.zip file
with zipfile.ZipFile(fungi_path, 'r') as zip_ref:
    zip_ref.extractall(fungi_output)

# Specify the correct path to the image data directory
image_data = fungi_output

pd.DataFrame(os.listdir(image_data),columns=['Files_Name'])

files = [i.replace("\\", "/") for i in glob.glob(image_data + "//*//*")]
np.random.shuffle(files)
labels = [os.path.dirname(i).split("/")[-1] for i in files]
data = zip(files, labels)
dataframe = pd.DataFrame(data, columns=["Image", "Label"])

dataframe

# Listing the 5 subdirectories in the extracted folder
classes = [os.path.join(fungi_output, o) for o in os.listdir(fungi_output)
           if os.path.isdir(os.path.join(fungi_output,o))]

# Initialize a DataFrame to store image data
image_dimensions = pd.DataFrame()

# Loop through each class folder to extract image paths and labels
for class_path in classes:
    class_name = os.path.basename(class_path)
    images = [os.path.join(class_path, f) for f in os.listdir(class_path) if os.path.isfile(os.path.join(class_path, f))]
    data = pd.DataFrame({'path': images, 'label': class_name})
    image_dimensions = pd.concat([image_dimensions, data], ignore_index=True)

# Display the last few rows of the data frame
print(image_dimensions.tail())

"""# Exploratory Data Analysis"""

# Visualize 5 images from each folder
folders = dataframe['Label'].unique()

for folder in folders:
    folder_images = dataframe[dataframe['Label'] == folder]['Image'][:5]

    fig, axs = plt.subplots(1, 5, figsize=(15, 3))  # Adjust figsize as needed

    for i, image_path in enumerate(folder_images):
        img = mpimg.imread(image_path)
        axs[i].imshow(img)
        axs[i].axis('off')

    plt.suptitle(f"Images from folder {folder}")
    plt.show()

"""## Visualization- Bar Chart to check class balance"""

# Create style for plot
sns.set(style="whitegrid")

# Create a countplot with different colors for each category
ax = sns.countplot(x=dataframe["Label"], palette="Set3", edgecolor='black')

# Annotate each bar with its count
for p in ax.patches:
    ax.annotate(f'{p.get_height()}', (p.get_x() + p.get_width() / 2., p.get_height()),
                ha='center', va='center', xytext=(0, 10), textcoords='offset points')

plt.xticks(rotation=50)
plt.grid(False)  # Turn off grid lines
plt.show()

"""# Data Augmentation- Image Enhancing"""

# Create a directory to save augmented images
augmented_dir = "/content/drive/MyDrive/DS4002/AugmentedImages"
os.makedirs(augmented_dir, exist_ok=True)

# Data augmentation settings
datagen = ImageDataGenerator(
    rotation_range=40,
    width_shift_range=0.2,
    height_shift_range=0.2,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True,
    fill_mode='nearest'
)

# Apply data augmentation to each image and save the augmented images
for index, row in dataframe.iterrows():
    print(row['Image'])
    img = load_img(row['Image'])
    x = img_to_array(img)
    x = x.reshape((1,) + x.shape)

    # Generate augmented images
    i = 0
    for batch in datagen.flow(x, batch_size=1, save_to_dir=augmented_dir, save_prefix=row['Label'], save_format='jpeg'):
        i += 1
        if i >= 2:  # Generate 5 augmented images for each original image
            break

# Assuming augmented_dir is the directory where augmented images are saved
augmented_dir = "/content/drive/MyDrive/DS4002/AugmentedImages"

# Create an empty DataFrame to store information about augmented images
augmented_dataframe = pd.DataFrame(columns=['Image', 'Label'])

# Iterate through the augmented images directory
for filename in os.listdir(augmented_dir):
    # Assuming the file names are in the format "label_image_index.jpeg"
    label = filename.split('_')[0]

    # Create the file path
    filepath = os.path.join(augmented_dir, filename)

    #Append the information to the DataFrame
    augmented_dataframe = augmented_dataframe.append({'Image': filepath, 'Label': label}, ignore_index=True)

# Display the first few rows of the augmented DataFrame
# print(augmented_dataframe)
# print(augmented_dataframe.shape)

"""## Reclassifying and Viewing Enhanced Images"""

def sort_images(base_dir):
    # Define the target folders based on prefixes
    target_folders = ['H1', 'H2', 'H3', 'H5', 'H6']

    # Create target folders if they don't exist
    for folder in target_folders:
        os.makedirs(os.path.join(base_dir, folder), exist_ok=True)

    # Dictionary to track filenames to avoid duplicates
    seen_filenames = {}

    # Iterate over files in the base directory
    for filename in os.listdir(base_dir):
        filepath = os.path.join(base_dir, filename)

        # Skip if it's a directory
        if os.path.isdir(filepath):
            continue

        # Check if the file starts with one of the prefixes
        for prefix in target_folders:
            if filename.startswith(prefix):
                target_path = os.path.join(base_dir, prefix, filename)

                # Check for duplicates
                if filename not in seen_filenames:
                    # Move file to the corresponding folder
                    shutil.move(filepath, target_path)
                    seen_filenames[filename] = True
                else:
                    # Remove duplicate file
                    os.remove(filepath)

# Usage
base_dir = "/content/drive/MyDrive/DS4002/AugmentedImages"
sort_images(base_dir)

enhanced_path = "/content/drive/MyDrive/DS4002/AugmentedImages"
enhanced_images = enhanced_path

files_new = [i.replace("\\", "/") for i in glob.glob(enhanced_images + "//*//*")]
np.random.shuffle(files_new)
labels1 = [os.path.dirname(i).split("/")[-1] for i in files]
data_new = zip(files_new, labels1)
enhanced_df = pd.DataFrame(data_new, columns=["Image", "Label"])

# Visualize 5 images from each folder
folders = enhanced_df['Label'].unique()

for folder in folders:
    folder_images = enhanced_df[enhanced_df['Label'] == folder]['Image'][:5]

    fig, axs = plt.subplots(1, 5, figsize=(15, 3))  # Adjust figsize as needed

    for i, image_path in enumerate(folder_images):
        img = mpimg.imread(image_path)
        axs[i].imshow(img)
        axs[i].axis('off')

    plt.suptitle(f"Images from folder {folder}")
    plt.show()

"""## Bar Chart Visualization"""

#preliminary EDA
grouped = enhanced_dimensions.groupby('label').size().reset_index(name='count')
grouped['proportion'] = grouped['count'] / grouped['count'].sum()

print(grouped)

#making a graph for EDA
colors = ['pink', 'green', 'yellow', 'skyblue', 'orange']
graph = plt.bar(grouped['label'], grouped['count'], color = colors)
plt.xlabel("Label")
plt.ylabel("Count")
plt.title("Data Visualization")

for bar in graph:
    yval = bar.get_height()
    plt.text(bar.get_x() + bar.get_width()/2, yval, int(yval), va='bottom', ha='center')


plt.show()

enhanced_images = enhanced_path

# Listing the 5 subdirectories in the extracted folder
classes = [os.path.join(enhanced_images, o) for o in os.listdir(enhanced_images)
           if os.path.isdir(os.path.join(enhanced_images,o))]

# Initialize a DataFrame to store image data
enhanced_dimensions = pd.DataFrame()

# Loop through each class folder to extract image paths and labels
for class_path in classes:
    class_name = os.path.basename(class_path)
    images = [os.path.join(class_path, f) for f in os.listdir(class_path) if os.path.isfile(os.path.join(class_path, f))]
    data = pd.DataFrame({'path': images, 'label': class_name})
    enhanced_dimensions = pd.concat([enhanced_dimensions, data], ignore_index=True)

# Display the last few rows of the data frame
print(enhanced_dimensions.tail())

"""## Data Processing: Balancing Class Weights"""

#Balancing the dataset by removing half of the images from the class with the most images
max_class = grouped[grouped['count'] == grouped['count'].max()]['label'].values[0]
max_class_paths = enhanced_dimensions[enhanced_dimensions['label'] == max_class]['path'].tolist()

# Shuffle the paths randomly
random.shuffle(max_class_paths)

# Determine the number of paths to keep
num_to_keep = len(max_class_paths) // 2

# Select the first num_to_keep paths after shuffling
selected_paths = max_class_paths[:num_to_keep]

# Filter out the selected paths from the dataset
enhanced_dimensions = enhanced_dimensions[~enhanced_dimensions['path'].isin(selected_paths)]

# Recheck the distribution after balancing
grouped = enhanced_dimensions.groupby('label').size().reset_index(name='count')
grouped['proportion'] = grouped['count'] / grouped['count'].sum()
print(grouped)

"""# Model I: Convolutional Neural Network from scratch"""

#initializing CNN and adding a convolutional layer
model=Sequential()
model.add(Conv2D(filters=16,kernel_size=2,padding="same",activation="relu",input_shape=(500,500,3))) #3 is for RGB


#doing a Pooling operation to downsample our image
model.add(MaxPooling2D(pool_size=2)) #we are choosing to do MaxPooling. This also helps our model pick up on variation!


#adding 2 more convolutional layers
model.add(Conv2D(filters=32,kernel_size=2,padding="same",activation ="relu"))
model.add(MaxPooling2D(pool_size=2)) #notice how we are pooling everytime
model.add(Conv2D(filters=64,kernel_size=2,padding="same",activation="relu"))
model.add(MaxPooling2D(pool_size=2)) #with filter numbers 32 and 64

#flattening operation
model.add(Flatten())

#now we are taking our flattened info and will then use it to build the artificial neural network
model.add(Dense(500,activation="relu"))
model.add(Dense(5,activation="softmax")) #using Keras to do this. softmax is used to take our outputs of neural network and build probabilities of each possible outcome in our classes

##now our basic model is done. let us compile the model
model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])

X = enhanced_dimensions['path']
y = enhanced_dimensions['label']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)  # 20% data as test set

from tensorflow.keras.preprocessing.image import ImageDataGenerator

# creating our train and test data
datagen = ImageDataGenerator(rescale=1./255)
train_df = pd.DataFrame({'path': X_train, 'label': y_train})
test_df = pd.DataFrame({'path': X_test, 'label': y_test})

train_generator = datagen.flow_from_dataframe(
    dataframe=train_df,
    x_col='path',
    y_col='label',
    target_size=(500, 500),  # Adjust as needed
    batch_size=32,          # Adjust as needed
    class_mode='categorical')

test_generator = datagen.flow_from_dataframe(
    dataframe=test_df,
    x_col='path',
    y_col='label',
    target_size=(500, 500),  # Adjust as needed
    batch_size=32,          # Adjust as needed
    class_mode='categorical')


early_stop = EarlyStopping(monitor='val_loss', patience=2, verbose=1)

r = model.fit(
    train_generator,
    validation_data=test_generator,
    epochs=10,
    steps_per_epoch=len(train_generator),
    validation_steps=len(test_generator), callbacks=[early_stop]
)


plt.plot(r.history['loss'], label='train loss')
plt.plot(r.history['val_loss'], label='val loss')
plt.legend()
plt.show()
plt.savefig('LossVal_loss')

plt.plot(r.history['accuracy'], label='train acc')
plt.plot(r.history['val_accuracy'], label='val acc')
plt.legend()
plt.show()
plt.savefig('AccVal_acc')

"""# Model II: VGG19 Model

## Data Partitioning
"""

train_data_dir = enhanced_path
batch_size = 32
target_size = (224,224)
validation_split = 0.2
train= tf.keras.preprocessing.image_dataset_from_directory(
    train_data_dir,
    validation_split=validation_split,
    subset="training",
    seed=100,
    image_size=target_size,
    batch_size=batch_size,
)
validation= tf.keras.preprocessing.image_dataset_from_directory(
    train_data_dir,
    validation_split=validation_split,
    subset="validation",
    seed=200,
    image_size=target_size,
    batch_size=batch_size,
)

class_names = train.class_names
class_names

plt.figure(figsize=(15, 20))
for images, labels in train.take(1):
    for i in range(8):
        ax = plt.subplot(8, 4, i + 1)
        plt.imshow(images[i].numpy().astype("uint8"))
        plt.title(class_names[labels[i]])
        plt.axis("off")

"""## Model Creation"""

# Create VGG19 base model
base_model = tf.keras.applications.VGG19(input_shape=(224, 224, 3), include_top=False, weights='imagenet')
base_model.trainable = False

# Create a sequential model
keras_model = keras.models.Sequential()

# Add the VGG19 base model to the sequential model
keras_model.add(base_model)

# Flatten the output of the base model
keras_model.add(keras.layers.Flatten())

# Add dropout layer
keras_model.add(keras.layers.Dropout(0.5))

# Add dense layer with softmax activation for classification
keras_model.add(keras.layers.Dense(5, activation=tf.nn.softmax))

# Display model summary
keras_model.summary()

checkpoint =ModelCheckpoint("my_keras_model.h5", save_best_only=True)

early_stopping =EarlyStopping(patience=5, restore_best_weights=True)

keras_model.compile(optimizer ='Adam',loss='sparse_categorical_crossentropy', metrics=['accuracy'])
hist=keras_model.fit_generator(train,epochs=20,validation_data=validation,callbacks=[checkpoint,early_stopping])

score, acc = keras_model.evaluate(validation)
print('Test Loss =', score)
print('Test Accuracy =', acc)

hist_=pd.DataFrame(hist.history)
hist_

"""## Evaluation Metrics"""

plt.figure(figsize=(15,5))
plt.subplot(1,2,1)
plt.plot(hist_['loss'],label='Train_Loss')
plt.plot(hist_['val_loss'],label='Validation_Loss')
plt.title('Train_Loss & Validation_Loss',fontsize=20)
plt.legend()
plt.subplot(1,2,2)
plt.plot(hist_['accuracy'],label='Train_Accuracy')
plt.plot(hist_['val_accuracy'],label='Validation_Accuracy')
plt.title('Train_Accuracy & Validation_Accuracy',fontsize=20)
plt.legend()

X_val,y_val,y_pred=[],[],[]
for images, labels in validation:
    y_val.extend(labels.numpy())
    X_val.extend(images.numpy())
predictions=keras_model.predict(np.array(X_val))
for i in predictions:
    y_pred.append(np.argmax(i))
df=pd.DataFrame()
df['Actual'],df['Prediction']=y_val,y_pred
df

plt.figure(figsize=(25,25))
for i in range(32):
    ax = plt.subplot(8, 4, i + 1)
    plt.imshow(X_val[i].astype("uint8"))
    plt.title(f'{class_names[y_val[i]]} :: {class_names[y_pred[i]]}')
    plt.axis("off")

Acc = accuracy_score(y_val,y_pred)
print("accuracy is: {0:.3f}%".format(Acc * 100))

"""# Model III: VGG19 Model with UnEnhanced Images

## Data Partitioning
"""

train_data_dir = fungi_output
batch_size = 32
target_size = (224,224)
validation_split = 0.2
train= tf.keras.preprocessing.image_dataset_from_directory(
    train_data_dir,
    validation_split=validation_split,
    subset="training",
    seed=100,
    image_size=target_size,
    batch_size=batch_size,
)
validation= tf.keras.preprocessing.image_dataset_from_directory(
    train_data_dir,
    validation_split=validation_split,
    subset="validation",
    seed=200,
    image_size=target_size,
    batch_size=batch_size,
)

class_names = train.class_names
class_names

plt.figure(figsize=(15, 20))
for images, labels in train.take(1):
    for i in range(8):
        ax = plt.subplot(8, 4, i + 1)
        plt.imshow(images[i].numpy().astype("uint8"))
        plt.title(class_names[labels[i]])
        plt.axis("off")

"""## Model Creation"""

# Create VGG19 base model
base_model = tf.keras.applications.VGG19(input_shape=(224, 224, 3), include_top=False, weights='imagenet')
base_model.trainable = False

# Create a sequential model
keras_model = keras.models.Sequential()

# Add the VGG19 base model to the sequential model
keras_model.add(base_model)

# Flatten the output of the base model
keras_model.add(keras.layers.Flatten())

# Add dropout layer
keras_model.add(keras.layers.Dropout(0.5))

# Add dense layer with softmax activation for classification
keras_model.add(keras.layers.Dense(5, activation=tf.nn.softmax))

# Display model summary
keras_model.summary()

checkpoint =ModelCheckpoint("my_keras_model.h5", save_best_only=True)

early_stopping =EarlyStopping(patience=5, restore_best_weights=True)

keras_model.compile(optimizer ='Adam',loss='sparse_categorical_crossentropy', metrics=['accuracy'])
hist=keras_model.fit_generator(train,epochs=20,validation_data=validation,callbacks=[checkpoint,early_stopping])

"""## Evaluation Metrics"""

score, acc = keras_model.evaluate(validation)
print('Test Loss =', score)
print('Test Accuracy =', acc)

hist_=pd.DataFrame(hist.history)
hist_

plt.figure(figsize=(15,5))
plt.subplot(1,2,1)
plt.plot(hist_['loss'],label='Train_Loss')
plt.plot(hist_['val_loss'],label='Validation_Loss')
plt.title('Train_Loss & Validation_Loss',fontsize=20)
plt.legend()
plt.subplot(1,2,2)
plt.plot(hist_['accuracy'],label='Train_Accuracy')
plt.plot(hist_['val_accuracy'],label='Validation_Accuracy')
plt.title('Train_Accuracy & Validation_Accuracy',fontsize=20)
plt.legend()

X_val,y_val,y_pred=[],[],[]
for images, labels in validation:
    y_val.extend(labels.numpy())
    X_val.extend(images.numpy())
predictions=keras_model.predict(np.array(X_val))
for i in predictions:
    y_pred.append(np.argmax(i))
df=pd.DataFrame()
df['Actual'],df['Prediction']=y_val,y_pred
df

plt.figure(figsize=(25,25))
for i in range(32):
    ax = plt.subplot(8, 4, i + 1)
    plt.imshow(X_val[i].astype("uint8"))
    plt.title(f'{class_names[y_val[i]]} :: {class_names[y_pred[i]]}')
    plt.axis("off")

ax= plt.subplot()
CM = confusion_matrix(y_val,y_pred)
sns.heatmap(CM, annot=True, fmt='g', ax=ax,cbar=False,cmap='RdBu')
ax.set_xlabel('Predicted labels')
ax.set_ylabel('True labels')
ax.set_title('Confusion Matrix')
plt.show()
CM

Acc = accuracy_score(y_val,y_pred)
print("accuracy is: {0:.3f}%".format(Acc * 100))